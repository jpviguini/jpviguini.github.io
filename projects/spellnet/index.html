<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;600;700;800&family=Frank+Ruhl+Libre:wght@200;300;400;500;600&family=Encode+Sans+Semi+Condensed:wght@400&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" type="text/css" href="/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="/css/all.min.css">
    <link disabled id="dark-mode-theme" rel="stylesheet" href="/css/dark.css">
    <link rel="stylesheet" type="text/css" href="/css/style.css">
    <link rel="stylesheet" type="text/css" href="/css/my_style.css">
    
    
    
    <title>Joao Correa | SpellNet: Real-Time Multilingual Sign Language Detection</title>
    <meta name="description" content="A system for real-time detection and recognition of sign languages (LIBRAS and ASL), enabling inclusion and accessibility.">
</head><body><nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="https://jpviguini.github.io/">
        
        <b style="font-weight: 800;">JC</b>
        
    </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>










</nav><div id="content">

<div class="container">
    <div class="py-4 rounded-3">
        <div class="container-fluid py-2 align-items-center d-flex justify-content-center">
            
            
            <h1 class="display-2 mb-4">SpellNet: Real-Time Multilingual Sign Language Detection</h1>
            
        </div>
        
        <p class="text-center fs-4 fst-italic serif">A system for real-time detection and recognition of sign languages (LIBRAS and ASL), enabling inclusion and accessibility.</p>
        
        <div class="text-center pt-4">
            
        </div>
    </div>
    <div class="row justify-content-center mb-5">
        <div class="col-12">
            
            <hr class="dropdown-divider">
            <div class="row justify-content-between">
                <div class="col-sm-4">
                    
                </div>
                <div class="col-sm-8" style="text-align: right;">
                    
                
                
                    
                    <span class="badge tag-badge">Computer Vision</span>
                    
                    <span class="badge tag-badge">Tensorflow</span>
                    
                    <span class="badge tag-badge">CNNs</span>
                    
                    <span class="badge tag-badge">Feature extraction</span>
                    
                    <span class="badge tag-badge">LSTM</span>
                    
                
                </div>
            </div>
        </div>
    </div>

    <div class="container-fluid py-2">
        <div class="serif main-content">
            <div style="text-align: center; margin-bottom: 2rem;">
  <img src="/images/spellnet/featured_spellnet.png" 
        style="width: 60%; max-width: 800px;"></img>
</div>
<h2 id="about-the-project">About the project</h2>
<p><strong>SpellNet</strong> is a research and development project that leverages artificial intelligence and computer vision to enable <strong>real-time recognition of multiple sign languages</strong>, with initial focus on LIBRAS (Brazilian Sign Language) and ASL (American Sign Language).</p>
<p>The system uses CNNs (MobileNetV2) trained on sign language datasets to classify hand gestures and integrate them into accessible applications. Beyond recognition, the project also explores the potential of <strong>multilingual support</strong>, allowing users from different regions to interact seamlessly.</p>
<p>Currently, we are integrating <strong>LSTM (Long Short-Term Memory networks)</strong> to handle dynamic gestures, expanding SpellNet‚Äôs ability from recognizing static signs to capturing more complex motion sequences in real-time.</p>
<p>This initiative aims to foster <strong>inclusion and accessibility</strong> by breaking communication barriers for the Deaf community, while also serving as a platform for experimentation in gesture recognition, multimodal interaction, and AI-powered accessibility tools.</p>
<h2 id="features">Features:</h2>
<ul>
<li>üñê <strong>Real-time sign language detection</strong> using deep learning and computer vision.</li>
<li>üåé <strong>Support for multiple sign languages</strong> (starting with LIBRAS and ASL).</li>
<li>‚ö° <strong>Web-based interface</strong> for fast and easy testing.</li>
<li>üëê <strong>Accessibility-focused</strong>, bridging communication between deaf and hearing individuals.</li>
</ul>
<hr>
<h2 id="results">Results</h2>
<ul>
<li>üìÇ Released an open-source dataset: <strong>5000</strong> images per class in ASL and <strong>3700</strong> images per class in LIBRAS.</li>
<li>‚úÖ Achieved <strong>90% accuracy</strong> on LIBRAS static gesture real-time recognition.</li>
<li>‚úÖ Achieved <strong>79% accuracy</strong> on ASL static gesture real-time recognition.</li>
<li>üöÄ Ongoing experiments with <strong>LSTM for dynamic gestures</strong> are showing promising improvements in real-time performance.</li>
</ul>
<hr>
<p>The project is open-source, and the source code is available on <a href="https://github.com/gruporaia/SpellNet">GitHub</a>.<br>
More details about the project can be found on the <a href="https://grupo-raia.org/projetos/projeto/spellnet">official page</a>.</p>

        </div>
    </div>
</div>


        </div><div class="footer-container row justify-content-between">
    <div class="col-sm-4">
        <p class="footer">Jo√£o ¬© 2025 </p>
    </div>
    <div class="col-sm-6 d-flex flex-row-reverse">
        
        <a class="footer-social px-2"  href="https://github.com/jpviguini" target="_blank"><i class="fab fa-github"></i></a>
        
        <a class="footer-social px-2"  href="https://www.linkedin.com/in/jpviguini/" target="_blank"><i class="fab fa-linkedin-in"></i></a>
        
    </div>
</div>
<script src="/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/js/jquery.min.js"></script>
<script src="/js/isotope.pkgd.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous" async></script>
<script src="/js/dark.js"></script>
<script src="/js/isotope.js"></script>
<script src="/js/mermaid.min.js"></script>
<script>mermaid.initialize({ startOnLoad: true, securityLevel: 'loose'});</script></body>
</html>
